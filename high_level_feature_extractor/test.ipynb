{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvkiselev/projects/dpl/venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vvkiselev/projects/dpl/venv/lib64/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wave\n",
    "import sys\n",
    "import soundfile as sf\n",
    "# from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from dataclasses import (\n",
    "    dataclass,\n",
    "    asdict,\n",
    ")\n",
    "from typing import (\n",
    "    Optional,\n",
    "    Callable,\n",
    "    Set,\n",
    "    Generator,\n",
    "    List,\n",
    "    Tuple,\n",
    "    Union,\n",
    "    Dict,\n",
    ")\n",
    "import time\n",
    "import dill\n",
    "import logging\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import transformers\n",
    "import torch\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from enum import Enum\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# from bdw.check import Check\n",
    "\n",
    "sys.path.append('..')\n",
    "from audio import (\n",
    "    Audio,\n",
    "    WAVFilePathInitArgs,\n",
    ")\n",
    "from text.profanity import (\n",
    "    PROFANITY_WORD_FILTER_LANG_NAME,\n",
    ")\n",
    "from configs.base import (\n",
    "    RB_OPEN_FILE_MODE,\n",
    "    SECONDS_QUANTITY_IN_MINUTE,\n",
    "    TAB,\n",
    "    RUSSIAN_VOWELS,\n",
    "    WB_OPEN_FILE_MODE,\n",
    "    DROP_DUPLICATES_KEEP_FIRST,\n",
    "    JOIN_HOW_INNER,\n",
    ")\n",
    "from configs.paths import (\n",
    "    DUSHA_CROWD_TRAIN_FILE_PATH,\n",
    "    DUSHA_CROWD_TEST_FILE_PATH,\n",
    "    DUSHA_CROWD_TRAIN_WAVS_DIR_PATH,\n",
    "    DUSHA_CROWD_TEST_WAVS_DIR_PATH,\n",
    "    PROCESSED_DUSHA_CROWD_TRAIN_HLF_LAST_VERSION_FILE_PATH,\n",
    "    PROCESSED_DUSHA_CROWD_TEST_HLF_LAST_VERSION_FILE_PATH,\n",
    "    DO_NOT_EXTRACTED_FEATUERS_HASHES_FILE_PATH,\n",
    ")\n",
    "from configs.report_tables_format import (\n",
    "    classification_report_formatted,\n",
    ")\n",
    "from processing.text.normalization import (\n",
    "    normalized_tokens_2_normalized_text,\n",
    "    text_2_normalized_text,\n",
    ")\n",
    "from high_level_feature_extractor.text.profanity import (\n",
    "    text_2_is_contain_swear_words,\n",
    ")\n",
    "from high_level_feature_extractor.text.all import (\n",
    "    TranscriptionHighLevelFeatures,\n",
    ")\n",
    "from high_level_feature_extractor.extractor import (\n",
    "    HighLevelSpeechFeatures,\n",
    "    HashHLF,\n",
    "    hash_HLF_list_2_df,\n",
    "    PronounceSpeed,\n",
    ")\n",
    "from high_level_feature_extractor.extract import (\n",
    "    raw_crowd_2_HLF,\n",
    ")\n",
    "from utils.dataclass import (\n",
    "    flatten_dict,\n",
    ")\n",
    "from volume.human_speech import (\n",
    "    HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    ")\n",
    "from configs.paths import (\n",
    "    PROCESSED_DUSHA_CROWD_TRAIN_DIR_PATH,\n",
    "    PROCESSED_DUSHA_CROWD_TEST_DIR_PATH,\n",
    "    PROCESSED_DUSHA_CROWD_TRAIN_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH,\n",
    "    PROCESSED_DUSHA_CROWD_TEST_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH,\n",
    ")\n",
    "from models.config import (\n",
    "    TORCH_TENSORS_KEYWOED,\n",
    "    ATTENTION_MASK_KEYWORD,\n",
    ")\n",
    "from models.text_embedding.ru_en_RoSBERTa import (\n",
    "    DEVICE as ROSBERTA_DEVICE,\n",
    "    NORMALIZE_P as ROSBERTA_NORMALIZE_P,\n",
    "    NORMALIZE_DIM as ROSBERTA_NORMALIZE_DIM,\n",
    "    CLAMP_MIN,\n",
    ")\n",
    "from config import (\n",
    "    SPEAKER_TEXT_FIELD_NAME,\n",
    ")\n",
    "from utils.parallel_processing import (\n",
    "    divide_into_chunks,\n",
    ")\n",
    "from configs.datasets.dusha import (\n",
    "    HASH_ID_COLUMN_NAME,\n",
    "    GoldenEmo,\n",
    "    SPEAKER_EMOTION_FIELD_NAME,\n",
    ")\n",
    "from processing.text.normalization import (\n",
    "    text_to_normalized_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_AUDIO_PATH:Path = Path('/data01/vvkiselev/data/other/dpl/dusha/crowd/crowd_train/wavs/000039c2bc753aa5a776621a4707eb73.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(hash='000039c2bc753aa5a776621a4707eb73', sample_width=2, sr=16000, n_frames=165120, data=array([ 0,  0,  0, ..., -2,  6, -9], dtype=int16), n_channels=1, _transcription='ахах, пиздец')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio_example:Audio = Audio.wav_file_path_init(path=EXAMPLE_AUDIO_PATH, transcription='ахах, пиздец')\n",
    "arguments:WAVFilePathInitArgs = WAVFilePathInitArgs(path=EXAMPLE_AUDIO_PATH, transcription='ахах, пиздец')\n",
    "audio_example:Audio = Audio.wav_file_path_init(arguments=arguments)\n",
    "audio_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(tfidf_matrix) = <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HighLevelSpeechFeatures(loudness=59.77829826935232, HF_power_ratio=0.054469042401762625, pronounce_speed=PronounceSpeed(WPS=1.065891472868217, LPS=0.9689922480620154, SPS=0.38759689922480617), transcription_features=TranscriptionHighLevelFeatures(mean_words_length=5.0, profanity_words_ratio=0.5, meaning=4.454233000760066e-05))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HLF_example:HighLevelSpeechFeatures = HighLevelSpeechFeatures.wav_path_init(path=EXAMPLE_AUDIO_PATH, transcription='бля зачем')\n",
    "HLF_example:HighLevelSpeechFeatures = HighLevelSpeechFeatures.audio_init(audio=audio_example)\n",
    "HLF_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(906953, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>duration</th>\n",
       "      <th>annotator_emo</th>\n",
       "      <th>golden_emo</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>speaker_emo</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>475e76f77ac1ed7cabafca740b15b32a</td>\n",
       "      <td>wavs/475e76f77ac1ed7cabafca740b15b32a.wav</td>\n",
       "      <td>2.453000</td>\n",
       "      <td>angry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>не надо не надо не надо не надо</td>\n",
       "      <td>angry</td>\n",
       "      <td>fa136da095807ea6cd18dd6e2f58d4d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2f9438ef68395c70a8714dc373a49d11</td>\n",
       "      <td>wavs/2f9438ef68395c70a8714dc373a49d11.wav</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>фозил кори mp три</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3d436884cbbe25373914f8768de494f7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9937036a9c0dba20eecbffddd00f2be2</td>\n",
       "      <td>wavs/9937036a9c0dba20eecbffddd00f2be2.wav</td>\n",
       "      <td>4.341750</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb0ae78586a235018103acec22a80a8f</td>\n",
       "      <td>wavs/fb0ae78586a235018103acec22a80a8f.wav</td>\n",
       "      <td>3.900562</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>сколько стоит на керамбит</td>\n",
       "      <td>neutral</td>\n",
       "      <td>80bc833cf6b3f106d2e8991783a31e2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196dcf9e1aaac46c2aee45e7f6adfb92</td>\n",
       "      <td>wavs/196dcf9e1aaac46c2aee45e7f6adfb92.wav</td>\n",
       "      <td>4.780000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>афина когда закончится эта телепередача</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bd78f079676fa5f1ed17253c9a440cc6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            hash_id  \\\n",
       "0  475e76f77ac1ed7cabafca740b15b32a   \n",
       "1  2f9438ef68395c70a8714dc373a49d11   \n",
       "2  9937036a9c0dba20eecbffddd00f2be2   \n",
       "3  fb0ae78586a235018103acec22a80a8f   \n",
       "4  196dcf9e1aaac46c2aee45e7f6adfb92   \n",
       "\n",
       "                                  audio_path  duration annotator_emo  \\\n",
       "0  wavs/475e76f77ac1ed7cabafca740b15b32a.wav  2.453000         angry   \n",
       "1  wavs/2f9438ef68395c70a8714dc373a49d11.wav  4.640000       neutral   \n",
       "2  wavs/9937036a9c0dba20eecbffddd00f2be2.wav  4.341750       neutral   \n",
       "3  wavs/fb0ae78586a235018103acec22a80a8f.wav  3.900562       neutral   \n",
       "4  wavs/196dcf9e1aaac46c2aee45e7f6adfb92.wav  4.780000       neutral   \n",
       "\n",
       "   golden_emo                      annotator_id  \\\n",
       "0         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "1         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "2         2.0  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "3         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "4         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "\n",
       "                              speaker_text speaker_emo  \\\n",
       "0          не надо не надо не надо не надо       angry   \n",
       "1                        фозил кори mp три     neutral   \n",
       "2                                      NaN         NaN   \n",
       "3                сколько стоит на керамбит     neutral   \n",
       "4  афина когда закончится эта телепередача     neutral   \n",
       "\n",
       "                          source_id  \n",
       "0  fa136da095807ea6cd18dd6e2f58d4d0  \n",
       "1  3d436884cbbe25373914f8768de494f7  \n",
       "2                               NaN  \n",
       "3  80bc833cf6b3f106d2e8991783a31e2b  \n",
       "4  bd78f079676fa5f1ed17253c9a440cc6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79088, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>duration</th>\n",
       "      <th>annotator_emo</th>\n",
       "      <th>golden_emo</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>speaker_emo</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9961c53ca6eeb440b217e539fbf46c</td>\n",
       "      <td>wavs/9e9961c53ca6eeb440b217e539fbf46c.wav</td>\n",
       "      <td>5.82</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>я слушаю</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4282ddc30d71ef420e202e0c60391e9f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0166f65a30354db8282682b1a280e64c</td>\n",
       "      <td>wavs/0166f65a30354db8282682b1a280e64c.wav</td>\n",
       "      <td>3.70</td>\n",
       "      <td>sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>каким стал сбер</td>\n",
       "      <td>neutral</td>\n",
       "      <td>d70dc98ed56e9362eaefefb7b2827c8f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d49a6b560155831725a7bdc7d0a96099</td>\n",
       "      <td>wavs/d49a6b560155831725a7bdc7d0a96099.wav</td>\n",
       "      <td>4.38</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>где родился шерлок холмс</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0ee35d2abecf4272ecc8e1539b0839d8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c6852b0925797612d7b6724da8cbe7b4</td>\n",
       "      <td>wavs/c6852b0925797612d7b6724da8cbe7b4.wav</td>\n",
       "      <td>8.58</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>858305a5450b7bd1288ba0053b1cd1c1</td>\n",
       "      <td>открой в браузере ennio morricone</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0855e363c1787df1592f58f7a27ebe13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0166f65a30354db8282682b1a280e64c</td>\n",
       "      <td>wavs/0166f65a30354db8282682b1a280e64c.wav</td>\n",
       "      <td>3.70</td>\n",
       "      <td>sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a5562e26cd8f1949488a2d1e1e549d97</td>\n",
       "      <td>каким стал сбер</td>\n",
       "      <td>neutral</td>\n",
       "      <td>d70dc98ed56e9362eaefefb7b2827c8f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            hash_id  \\\n",
       "0  9e9961c53ca6eeb440b217e539fbf46c   \n",
       "1  0166f65a30354db8282682b1a280e64c   \n",
       "2  d49a6b560155831725a7bdc7d0a96099   \n",
       "3  c6852b0925797612d7b6724da8cbe7b4   \n",
       "4  0166f65a30354db8282682b1a280e64c   \n",
       "\n",
       "                                  audio_path  duration annotator_emo  \\\n",
       "0  wavs/9e9961c53ca6eeb440b217e539fbf46c.wav      5.82       neutral   \n",
       "1  wavs/0166f65a30354db8282682b1a280e64c.wav      3.70           sad   \n",
       "2  wavs/d49a6b560155831725a7bdc7d0a96099.wav      4.38       neutral   \n",
       "3  wavs/c6852b0925797612d7b6724da8cbe7b4.wav      8.58       neutral   \n",
       "4  wavs/0166f65a30354db8282682b1a280e64c.wav      3.70           sad   \n",
       "\n",
       "   golden_emo                      annotator_id  \\\n",
       "0         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "1         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "2         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "3         NaN  858305a5450b7bd1288ba0053b1cd1c1   \n",
       "4         NaN  a5562e26cd8f1949488a2d1e1e549d97   \n",
       "\n",
       "                        speaker_text speaker_emo  \\\n",
       "0                           я слушаю     neutral   \n",
       "1                    каким стал сбер     neutral   \n",
       "2           где родился шерлок холмс     neutral   \n",
       "3  открой в браузере ennio morricone     neutral   \n",
       "4                    каким стал сбер     neutral   \n",
       "\n",
       "                          source_id  \n",
       "0  4282ddc30d71ef420e202e0c60391e9f  \n",
       "1  d70dc98ed56e9362eaefefb7b2827c8f  \n",
       "2  0ee35d2abecf4272ecc8e1539b0839d8  \n",
       "3  0855e363c1787df1592f58f7a27ebe13  \n",
       "4  d70dc98ed56e9362eaefefb7b2827c8f  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_crowd_train = pd.read_csv(DUSHA_CROWD_TRAIN_FILE_PATH, sep=TAB)\n",
    "print(raw_crowd_train.shape)\n",
    "display(raw_crowd_train.head())\n",
    "\n",
    "raw_crowd_test = pd.read_csv(DUSHA_CROWD_TEST_FILE_PATH, sep=TAB)\n",
    "print(raw_crowd_test.shape)\n",
    "display(raw_crowd_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_id</th>\n",
       "      <th>audio_path</th>\n",
       "      <th>duration</th>\n",
       "      <th>annotator_emo</th>\n",
       "      <th>golden_emo</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>speaker_emo</th>\n",
       "      <th>source_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412403</th>\n",
       "      <td>5d9560dd2cba88b2dc87b6b4d5b6a29d</td>\n",
       "      <td>wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav</td>\n",
       "      <td>0.347875</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09184134bd1ddeb646205ba8e981fba8</td>\n",
       "      <td>фильмы меньшова</td>\n",
       "      <td>sad</td>\n",
       "      <td>24725b876b5e72993ec6c35688f754b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412437</th>\n",
       "      <td>5d9560dd2cba88b2dc87b6b4d5b6a29d</td>\n",
       "      <td>wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav</td>\n",
       "      <td>0.347875</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>076ffc89109d8d0cb8727de8f75b5c94</td>\n",
       "      <td>фильмы меньшова</td>\n",
       "      <td>sad</td>\n",
       "      <td>24725b876b5e72993ec6c35688f754b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412457</th>\n",
       "      <td>5d9560dd2cba88b2dc87b6b4d5b6a29d</td>\n",
       "      <td>wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav</td>\n",
       "      <td>0.347875</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62942acb4975e3cac00d06726a0dfd83</td>\n",
       "      <td>фильмы меньшова</td>\n",
       "      <td>sad</td>\n",
       "      <td>24725b876b5e72993ec6c35688f754b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414061</th>\n",
       "      <td>5d9560dd2cba88b2dc87b6b4d5b6a29d</td>\n",
       "      <td>wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav</td>\n",
       "      <td>0.347875</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a30fefe82e1e460f186efe6e9bbf9c58</td>\n",
       "      <td>фильмы меньшова</td>\n",
       "      <td>sad</td>\n",
       "      <td>24725b876b5e72993ec6c35688f754b8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hash_id  \\\n",
       "412403  5d9560dd2cba88b2dc87b6b4d5b6a29d   \n",
       "412437  5d9560dd2cba88b2dc87b6b4d5b6a29d   \n",
       "412457  5d9560dd2cba88b2dc87b6b4d5b6a29d   \n",
       "414061  5d9560dd2cba88b2dc87b6b4d5b6a29d   \n",
       "\n",
       "                                       audio_path  duration annotator_emo  \\\n",
       "412403  wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav  0.347875         other   \n",
       "412437  wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav  0.347875         other   \n",
       "412457  wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav  0.347875         other   \n",
       "414061  wavs/5d9560dd2cba88b2dc87b6b4d5b6a29d.wav  0.347875         other   \n",
       "\n",
       "        golden_emo                      annotator_id     speaker_text  \\\n",
       "412403         NaN  09184134bd1ddeb646205ba8e981fba8  фильмы меньшова   \n",
       "412437         NaN  076ffc89109d8d0cb8727de8f75b5c94  фильмы меньшова   \n",
       "412457         NaN  62942acb4975e3cac00d06726a0dfd83  фильмы меньшова   \n",
       "414061         NaN  a30fefe82e1e460f186efe6e9bbf9c58  фильмы меньшова   \n",
       "\n",
       "       speaker_emo                         source_id  \n",
       "412403         sad  24725b876b5e72993ec6c35688f754b8  \n",
       "412437         sad  24725b876b5e72993ec6c35688f754b8  \n",
       "412457         sad  24725b876b5e72993ec6c35688f754b8  \n",
       "414061         sad  24725b876b5e72993ec6c35688f754b8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_crowd_train[raw_crowd_train.hash_id == '5d9560dd2cba88b2dc87b6b4d5b6a29d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_crowd_train.hash_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184633, 17217)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_crowd_train.hash_id.unique()), len(raw_crowd_test.hash_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvkiselev/projects/dpl/venv/lib64/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(tokenizer=&lt;function text_to_normalized_tokens at 0x7f2e3b8b0400&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(tokenizer=&lt;function text_to_normalized_tokens at 0x7f2e3b8b0400&gt;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(tokenizer=<function text_to_normalized_tokens at 0x7f2e3b8b0400>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer:TfidfVectorizer = TfidfVectorizer(tokenizer=text_to_normalized_tokens)\n",
    "# tfs = tf_idf_vectorizer.fit_transform(['cat dog', 'dog bug'])\n",
    "\n",
    "# s = 'cat, dog, bug, bug'\n",
    "# response = tf_idf_vectorizer.transform([s])\n",
    "# print(response)\n",
    "# tf_idf_vectorizer\n",
    "tf_idf_vectorizer.fit(raw_crowd_train.speaker_text.dropna().unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_HLF_file(\n",
    "    HLF_file_path:Path = PROCESSED_DUSHA_CROWD_TRAIN_HLF_LAST_VERSION_FILE_PATH,\n",
    "    )->List[HashHLF]:\n",
    "    hash_HLF_list:List[HashHLF] = []\n",
    "    with open(HLF_file_path) as f:\n",
    "        for line in f:\n",
    "            el:Optional[HashHLF] = eval(eval(line)) if eval(line) is not None else None\n",
    "            if el is not None:\n",
    "                hash_HLF_list.append(el)\n",
    "                \n",
    "    return hash_HLF_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_crowd_2_raw_crowd_HLF_table_format(\n",
    "    raw_crowd:pd.DataFrame,\n",
    "    ):\n",
    "    raw_crowd_unique_hashes:pd.DataFrame = raw_crowd[~raw_crowd.hash_id.duplicated()]\n",
    "    # raw_crowd_train_unique_hashes_only_goldens:pd.DataFrame = raw_crowd_train_unique_hashes[~raw_crowd_train_unique_hashes.golden_emo.isna()]\n",
    "    raw_crowd_unique_hashes_with_speaker_emo:pd.DataFrame = raw_crowd_unique_hashes[~raw_crowd_unique_hashes.speaker_emo.isna()]\n",
    "    raw_crowd_unique_hashes_with_speaker_emo_with_speaker_text:pd.DataFrame = raw_crowd_unique_hashes_with_speaker_emo[~raw_crowd_unique_hashes_with_speaker_emo.speaker_text.isna()]\n",
    "    raw_crowd_unique_hashes_with_speaker_emo_with_speaker_text.set_index(HASH_ID_COLUMN_NAME, drop=True, inplace=True)\n",
    "    # raw_crowd_train_unique_hashes_only_goldens_with_speaker_text.golden_emo = raw_crowd_train_unique_hashes_only_goldens_with_speaker_text.golden_emo.apply(lambda x: GoldenEmo(round(x)).name)\n",
    "    # raw_crowd_train_unique_hashes_only_goldens.index.name=None\n",
    "    return raw_crowd_unique_hashes_with_speaker_emo_with_speaker_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLF_withspeaker_emottions_table(\n",
    "    raw_crowd:pd.DataFrame,\n",
    "    HLF_file_path:Path,\n",
    "    )->pd.DataFrame:\n",
    "    hash_HLF_list:List[HashHLF] = read_HLF_file(HLF_file_path=HLF_file_path)\n",
    "    HLF_table:pd.DataFrame = hash_HLF_list_2_df(l=hash_HLF_list)\n",
    "    raw_crowd_unique_hashes_with_speaker_emo_with_speaker_text:pd.DataFrame = raw_crowd_2_raw_crowd_HLF_table_format(raw_crowd=raw_crowd)\n",
    "\n",
    "    HLF_with_speaker_emotions:pd.DataFrame = HLF_table.join(raw_crowd_unique_hashes_with_speaker_emo_with_speaker_text.speaker_emo, how=JOIN_HOW_INNER)\n",
    "    return HLF_with_speaker_emotions\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182939, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loudness</th>\n",
       "      <th>HF_power_ratio</th>\n",
       "      <th>pronounce_speed_WPS</th>\n",
       "      <th>pronounce_speed_LPS</th>\n",
       "      <th>pronounce_speed_SPS</th>\n",
       "      <th>transcription_features_mean_words_length</th>\n",
       "      <th>transcription_features_profanity_words_ratio</th>\n",
       "      <th>speaker_emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475e76f77ac1ed7cabafca740b15b32a</th>\n",
       "      <td>74.022022</td>\n",
       "      <td>0.023930</td>\n",
       "      <td>9.783938</td>\n",
       "      <td>9.783938</td>\n",
       "      <td>4.891969</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2f9438ef68395c70a8714dc373a49d11</th>\n",
       "      <td>59.970772</td>\n",
       "      <td>0.033610</td>\n",
       "      <td>3.017241</td>\n",
       "      <td>3.017241</td>\n",
       "      <td>1.077586</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb0ae78586a235018103acec22a80a8f</th>\n",
       "      <td>67.891044</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>5.640212</td>\n",
       "      <td>5.640212</td>\n",
       "      <td>2.050986</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196dcf9e1aaac46c2aee45e7f6adfb92</th>\n",
       "      <td>46.226898</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>7.322176</td>\n",
       "      <td>7.322176</td>\n",
       "      <td>3.556485</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41d7f48ca93b01e4a01a4f34b40a69ff</th>\n",
       "      <td>56.706196</td>\n",
       "      <td>0.052391</td>\n",
       "      <td>8.438819</td>\n",
       "      <td>8.438819</td>\n",
       "      <td>4.008439</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   loudness  HF_power_ratio  \\\n",
       "475e76f77ac1ed7cabafca740b15b32a  74.022022        0.023930   \n",
       "2f9438ef68395c70a8714dc373a49d11  59.970772        0.033610   \n",
       "fb0ae78586a235018103acec22a80a8f  67.891044        0.008438   \n",
       "196dcf9e1aaac46c2aee45e7f6adfb92  46.226898        0.003612   \n",
       "41d7f48ca93b01e4a01a4f34b40a69ff  56.706196        0.052391   \n",
       "\n",
       "                                  pronounce_speed_WPS  pronounce_speed_LPS  \\\n",
       "475e76f77ac1ed7cabafca740b15b32a             9.783938             9.783938   \n",
       "2f9438ef68395c70a8714dc373a49d11             3.017241             3.017241   \n",
       "fb0ae78586a235018103acec22a80a8f             5.640212             5.640212   \n",
       "196dcf9e1aaac46c2aee45e7f6adfb92             7.322176             7.322176   \n",
       "41d7f48ca93b01e4a01a4f34b40a69ff             8.438819             8.438819   \n",
       "\n",
       "                                  pronounce_speed_SPS  \\\n",
       "475e76f77ac1ed7cabafca740b15b32a             4.891969   \n",
       "2f9438ef68395c70a8714dc373a49d11             1.077586   \n",
       "fb0ae78586a235018103acec22a80a8f             2.050986   \n",
       "196dcf9e1aaac46c2aee45e7f6adfb92             3.556485   \n",
       "41d7f48ca93b01e4a01a4f34b40a69ff             4.008439   \n",
       "\n",
       "                                  transcription_features_mean_words_length  \\\n",
       "475e76f77ac1ed7cabafca740b15b32a                                  3.000000   \n",
       "2f9438ef68395c70a8714dc373a49d11                                  3.500000   \n",
       "fb0ae78586a235018103acec22a80a8f                                  5.500000   \n",
       "196dcf9e1aaac46c2aee45e7f6adfb92                                  7.000000   \n",
       "41d7f48ca93b01e4a01a4f34b40a69ff                                  5.714286   \n",
       "\n",
       "                                  transcription_features_profanity_words_ratio  \\\n",
       "475e76f77ac1ed7cabafca740b15b32a                                           0.0   \n",
       "2f9438ef68395c70a8714dc373a49d11                                           0.0   \n",
       "fb0ae78586a235018103acec22a80a8f                                           0.0   \n",
       "196dcf9e1aaac46c2aee45e7f6adfb92                                           0.0   \n",
       "41d7f48ca93b01e4a01a4f34b40a69ff                                           0.0   \n",
       "\n",
       "                                 speaker_emo  \n",
       "475e76f77ac1ed7cabafca740b15b32a       angry  \n",
       "2f9438ef68395c70a8714dc373a49d11     neutral  \n",
       "fb0ae78586a235018103acec22a80a8f     neutral  \n",
       "196dcf9e1aaac46c2aee45e7f6adfb92     neutral  \n",
       "41d7f48ca93b01e4a01a4f34b40a69ff     neutral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HLF_with_speaker_emotions_train:pd.DataFrame = HLF_withspeaker_emottions_table(\n",
    "    raw_crowd=raw_crowd_train,\n",
    "    HLF_file_path=PROCESSED_DUSHA_CROWD_TRAIN_HLF_LAST_VERSION_FILE_PATH\n",
    ")\n",
    "print(HLF_with_speaker_emotions_train.shape)\n",
    "display(HLF_with_speaker_emotions_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17217, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loudness</th>\n",
       "      <th>HF_power_ratio</th>\n",
       "      <th>pronounce_speed_WPS</th>\n",
       "      <th>pronounce_speed_LPS</th>\n",
       "      <th>pronounce_speed_SPS</th>\n",
       "      <th>transcription_features_mean_words_length</th>\n",
       "      <th>transcription_features_profanity_words_ratio</th>\n",
       "      <th>speaker_emo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9e9961c53ca6eeb440b217e539fbf46c</th>\n",
       "      <td>51.384979</td>\n",
       "      <td>0.132317</td>\n",
       "      <td>1.202749</td>\n",
       "      <td>1.202749</td>\n",
       "      <td>0.687285</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0166f65a30354db8282682b1a280e64c</th>\n",
       "      <td>39.728794</td>\n",
       "      <td>0.249508</td>\n",
       "      <td>3.513514</td>\n",
       "      <td>3.513514</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d49a6b560155831725a7bdc7d0a96099</th>\n",
       "      <td>52.689034</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>4.794521</td>\n",
       "      <td>4.794521</td>\n",
       "      <td>1.598174</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c6852b0925797612d7b6724da8cbe7b4</th>\n",
       "      <td>63.896108</td>\n",
       "      <td>0.014975</td>\n",
       "      <td>3.379953</td>\n",
       "      <td>3.379953</td>\n",
       "      <td>0.699301</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64a7aa17132c3e4b7be1aaed5fc88090</th>\n",
       "      <td>69.266373</td>\n",
       "      <td>0.091205</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>1.976285</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   loudness  HF_power_ratio  \\\n",
       "9e9961c53ca6eeb440b217e539fbf46c  51.384979        0.132317   \n",
       "0166f65a30354db8282682b1a280e64c  39.728794        0.249508   \n",
       "d49a6b560155831725a7bdc7d0a96099  52.689034        0.029966   \n",
       "c6852b0925797612d7b6724da8cbe7b4  63.896108        0.014975   \n",
       "64a7aa17132c3e4b7be1aaed5fc88090  69.266373        0.091205   \n",
       "\n",
       "                                  pronounce_speed_WPS  pronounce_speed_LPS  \\\n",
       "9e9961c53ca6eeb440b217e539fbf46c             1.202749             1.202749   \n",
       "0166f65a30354db8282682b1a280e64c             3.513514             3.513514   \n",
       "d49a6b560155831725a7bdc7d0a96099             4.794521             4.794521   \n",
       "c6852b0925797612d7b6724da8cbe7b4             3.379953             3.379953   \n",
       "64a7aa17132c3e4b7be1aaed5fc88090             4.545455             4.545455   \n",
       "\n",
       "                                  pronounce_speed_SPS  \\\n",
       "9e9961c53ca6eeb440b217e539fbf46c             0.687285   \n",
       "0166f65a30354db8282682b1a280e64c             1.081081   \n",
       "d49a6b560155831725a7bdc7d0a96099             1.598174   \n",
       "c6852b0925797612d7b6724da8cbe7b4             0.699301   \n",
       "64a7aa17132c3e4b7be1aaed5fc88090             1.976285   \n",
       "\n",
       "                                  transcription_features_mean_words_length  \\\n",
       "9e9961c53ca6eeb440b217e539fbf46c                                  3.500000   \n",
       "0166f65a30354db8282682b1a280e64c                                  4.333333   \n",
       "d49a6b560155831725a7bdc7d0a96099                                  5.250000   \n",
       "c6852b0925797612d7b6724da8cbe7b4                                  5.800000   \n",
       "64a7aa17132c3e4b7be1aaed5fc88090                                  3.285714   \n",
       "\n",
       "                                  transcription_features_profanity_words_ratio  \\\n",
       "9e9961c53ca6eeb440b217e539fbf46c                                           0.0   \n",
       "0166f65a30354db8282682b1a280e64c                                           0.0   \n",
       "d49a6b560155831725a7bdc7d0a96099                                           0.0   \n",
       "c6852b0925797612d7b6724da8cbe7b4                                           0.0   \n",
       "64a7aa17132c3e4b7be1aaed5fc88090                                           0.0   \n",
       "\n",
       "                                 speaker_emo  \n",
       "9e9961c53ca6eeb440b217e539fbf46c     neutral  \n",
       "0166f65a30354db8282682b1a280e64c     neutral  \n",
       "d49a6b560155831725a7bdc7d0a96099     neutral  \n",
       "c6852b0925797612d7b6724da8cbe7b4     neutral  \n",
       "64a7aa17132c3e4b7be1aaed5fc88090    positive  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLF_with_speaker_emotions_test:pd.DataFrame = HLF_withspeaker_emottions_table(\n",
    "    raw_crowd=raw_crowd_test,\n",
    "    HLF_file_path=PROCESSED_DUSHA_CROWD_TEST_HLF_LAST_VERSION_FILE_PATH\n",
    ")\n",
    "print(HLF_with_speaker_emotions_test.shape)\n",
    "HLF_with_speaker_emotions_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.55      0.40      0.46      2853\n",
      "     neutral       0.48      0.89      0.62      7462\n",
      "    positive       0.33      0.00      0.00      2279\n",
      "         sad       0.37      0.10      0.16      4623\n",
      "\n",
      "    accuracy                           0.48     17217\n",
      "   macro avg       0.43      0.35      0.31     17217\n",
      "weighted avg       0.44      0.48      0.39     17217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = HLF_with_speaker_emotions_train.drop(columns=[SPEAKER_EMOTION_FIELD_NAME])  \n",
    "y_train = HLF_with_speaker_emotions_train[SPEAKER_EMOTION_FIELD_NAME]                \n",
    "\n",
    "X_test = HLF_with_speaker_emotions_test.drop(columns=[SPEAKER_EMOTION_FIELD_NAME])   \n",
    "y_test = HLF_with_speaker_emotions_test[SPEAKER_EMOTION_FIELD_NAME]                  \n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=100,       # Number of boosting iterations\n",
    "    learning_rate=0.1,    # Learning rate\n",
    "    depth=6,              # Depth of the trees\n",
    "    verbose=0           # Print progress every 100 iterations\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# If you have the true labels for the test set, evaluate accuracy\n",
    "if SPEAKER_EMOTION_FIELD_NAME in HLF_with_speaker_emotions_test.columns:\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_abbd0 th {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_abbd0 td {\n",
       "  background-color: white;\n",
       "  color: black;\n",
       "}\n",
       "#T_abbd0 table {\n",
       "  border: 1px solid black;\n",
       "  border-collapse: collapse;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_abbd0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_abbd0_level0_col0\" class=\"col_heading level0 col0\" >angry</th>\n",
       "      <th id=\"T_abbd0_level0_col1\" class=\"col_heading level0 col1\" >neutral</th>\n",
       "      <th id=\"T_abbd0_level0_col2\" class=\"col_heading level0 col2\" >positive</th>\n",
       "      <th id=\"T_abbd0_level0_col3\" class=\"col_heading level0 col3\" >sad</th>\n",
       "      <th id=\"T_abbd0_level0_col4\" class=\"col_heading level0 col4\" >macro avg</th>\n",
       "      <th id=\"T_abbd0_level0_col5\" class=\"col_heading level0 col5\" >weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_abbd0_level0_row0\" class=\"row_heading level0 row0\" >precision</th>\n",
       "      <td id=\"T_abbd0_row0_col0\" class=\"data row0 col0\" >0.55</td>\n",
       "      <td id=\"T_abbd0_row0_col1\" class=\"data row0 col1\" >0.48</td>\n",
       "      <td id=\"T_abbd0_row0_col2\" class=\"data row0 col2\" >0.33</td>\n",
       "      <td id=\"T_abbd0_row0_col3\" class=\"data row0 col3\" >0.37</td>\n",
       "      <td id=\"T_abbd0_row0_col4\" class=\"data row0 col4\" >0.43</td>\n",
       "      <td id=\"T_abbd0_row0_col5\" class=\"data row0 col5\" >0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abbd0_level0_row1\" class=\"row_heading level0 row1\" >recall</th>\n",
       "      <td id=\"T_abbd0_row1_col0\" class=\"data row1 col0\" >0.40</td>\n",
       "      <td id=\"T_abbd0_row1_col1\" class=\"data row1 col1\" >0.89</td>\n",
       "      <td id=\"T_abbd0_row1_col2\" class=\"data row1 col2\" >0.00</td>\n",
       "      <td id=\"T_abbd0_row1_col3\" class=\"data row1 col3\" >0.10</td>\n",
       "      <td id=\"T_abbd0_row1_col4\" class=\"data row1 col4\" >0.35</td>\n",
       "      <td id=\"T_abbd0_row1_col5\" class=\"data row1 col5\" >0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abbd0_level0_row2\" class=\"row_heading level0 row2\" >f1-score</th>\n",
       "      <td id=\"T_abbd0_row2_col0\" class=\"data row2 col0\" >0.46</td>\n",
       "      <td id=\"T_abbd0_row2_col1\" class=\"data row2 col1\" >0.62</td>\n",
       "      <td id=\"T_abbd0_row2_col2\" class=\"data row2 col2\" >0.00</td>\n",
       "      <td id=\"T_abbd0_row2_col3\" class=\"data row2 col3\" >0.16</td>\n",
       "      <td id=\"T_abbd0_row2_col4\" class=\"data row2 col4\" >0.31</td>\n",
       "      <td id=\"T_abbd0_row2_col5\" class=\"data row2 col5\" >0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abbd0_level0_row3\" class=\"row_heading level0 row3\" >support</th>\n",
       "      <td id=\"T_abbd0_row3_col0\" class=\"data row3 col0\" >2853.00</td>\n",
       "      <td id=\"T_abbd0_row3_col1\" class=\"data row3 col1\" >7462.00</td>\n",
       "      <td id=\"T_abbd0_row3_col2\" class=\"data row3 col2\" >2279.00</td>\n",
       "      <td id=\"T_abbd0_row3_col3\" class=\"data row3 col3\" >4623.00</td>\n",
       "      <td id=\"T_abbd0_row3_col4\" class=\"data row3 col4\" >17217.00</td>\n",
       "      <td id=\"T_abbd0_row3_col5\" class=\"data row3 col5\" >17217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2d03765d10>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification_report_formatted(y_true=y_test, y_pred=y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transcription_features_profanity_words_ratio    0.248369\n",
       "transcription_features_mean_words_length        0.241024\n",
       "loudness                                        0.201275\n",
       "HF_power_ratio                                  0.108504\n",
       "pronounce_speed_SPS                             0.100302\n",
       "pronounce_speed_LPS                             0.051853\n",
       "pronounce_speed_WPS                             0.048673\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_feature_importance:pd.Series = pd.Series(index=X_train.columns, data=model.feature_importances_ / (sum(model.feature_importances_))).sort_values(ascending=False)\n",
    "normalized_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch\n",
    "\n",
    "# # Initialize model and tokenizer\n",
    "# ROSBERTA_EMBEDDER_MODEL_NAME:str = 'ai-forever/ru-en-RoSBERTa'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(ROSBERTA_EMBEDDER_MODEL_NAME)\n",
    "# model = AutoModel.from_pretrained(ROSBERTA_EMBEDDER_MODEL_NAME)\n",
    "\n",
    "# def mean_pooling(model_output, attention_mask):\n",
    "#     token_embeddings = model_output.last_hidden_state\n",
    "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "#     return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# # Russian text processing\n",
    "# texts = [\"Ваш текст на русском языке здесь\"]\n",
    "# encoded_input = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model_output = model(**encoded_input)\n",
    "\n",
    "# # Choose pooling method\n",
    "# embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "# # embeddings = model_output.last_hidden_state[:,0]  # CLS pooling alternative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(\n",
    "    model_output:transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions, \n",
    "    attention_mask:torch.Tensor,\n",
    "    )->torch.Tensor:\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=CLAMP_MIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at /data01/vvkiselev/data/other/dpl/models/ru-en-RoSBERTa and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path:Path = Path('/data01/vvkiselev/data/other/dpl/models/ru-en-RoSBERTa')\n",
    "tokenizer:transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast = AutoTokenizer.from_pretrained(model_path)\n",
    "model:transformers.models.roberta.modeling_roberta.RobertaModel = AutoModel.from_pretrained(model_path).to(ROSBERTA_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_into_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_2_embeddings(\n",
    "    texts:List[str],\n",
    "    tokenizer:transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n",
    "    model:transformers.models.roberta.modeling_roberta.RobertaModel,\n",
    "    padding:bool=True,\n",
    "    truncation:bool=False,\n",
    "    return_tensors=TORCH_TENSORS_KEYWOED,\n",
    "    device=ROSBERTA_DEVICE,\n",
    "    attention_mask_keyword:str=ATTENTION_MASK_KEYWORD,\n",
    "    normalize_p:int = ROSBERTA_NORMALIZE_P,\n",
    "    normalize_dim:int = ROSBERTA_NORMALIZE_DIM,\n",
    "    )->torch.Tensor:\n",
    "    inputs:transformers.tokenization_utils_base.BatchEncoding = tokenizer(\n",
    "        texts,\n",
    "        padding=padding,\n",
    "        truncation=truncation,\n",
    "        return_tensors=return_tensors,\n",
    "    ).to(device)  # Move inputs to GPU\n",
    "\n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs:transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions = model(**inputs)\n",
    "\n",
    "    # Apply manual pooling\n",
    "    sentence_embeddings:torch.Tensor = mean_pooling(\n",
    "        model_output=outputs, \n",
    "        attention_mask=inputs[attention_mask_keyword],\n",
    "    )\n",
    "    embeddings:torch.Tensor = torch.nn.functional.normalize(\n",
    "        sentence_embeddings, \n",
    "        p=normalize_p, \n",
    "        dim=normalize_dim,\n",
    "    )\n",
    "\n",
    "    # print(f\"Embedding shape: {embeddings.shape}\")  # Output: torch.Size([1, 1024])\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2112, 1024])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs:torch.Tensor = texts_2_embeddings(\n",
    "    # texts=['Пример русского текста для анализа','я пошел гулять'],\n",
    "    texts=list(filter(lambda x: isinstance(x, str), list(raw_crowd_train[SPEAKER_TEXT_FIELD_NAME].head(5000).unique()))),\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    ")\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['не надо не надо не надо не надо',\n",
       " 'фозил кори mp три',\n",
       " nan,\n",
       " 'сколько стоит на керамбит',\n",
       " 'афина когда закончится эта телепередача']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_crowd_train.head()[SPEAKER_TEXT_FIELD_NAME].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcriptions_series_to_text_2_emb(\n",
    "    transcriptions_series:pd.Series,\n",
    "    tokenizer:transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast,\n",
    "    model:transformers.models.roberta.modeling_roberta.RobertaModel,\n",
    "    num_chunks:int,\n",
    "    padding:bool=True,\n",
    "    truncation:bool=False,\n",
    "    return_tensors=TORCH_TENSORS_KEYWOED,\n",
    "    device=ROSBERTA_DEVICE,\n",
    "    attention_mask_keyword:str=ATTENTION_MASK_KEYWORD,\n",
    "    normalize_p:int = ROSBERTA_NORMALIZE_P,\n",
    "    normalize_dim:int = ROSBERTA_NORMALIZE_DIM,\n",
    "    )->Dict[str, torch.Tensor]:\n",
    "    unique_texts:List[str] = list(\n",
    "        filter(\n",
    "            lambda x: isinstance(x, str), \n",
    "            list(transcriptions_series.unique())\n",
    "        )\n",
    "    )\n",
    "    print(f'len(unique_texts) = {len(unique_texts)}')\n",
    "\n",
    "    chunks:List[List[str]] = divide_into_chunks(unique_texts, num_chunks)\n",
    "    unique_text_2_embedding:Dict[str, torch.Tensor] = {}\n",
    "    for chunk in tqdm(chunks):\n",
    "        chunk_embeddings:torch.Tensor = texts_2_embeddings(\n",
    "            texts=chunk,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "            padding=padding,\n",
    "            truncation=truncation,\n",
    "            return_tensors=return_tensors,\n",
    "            device=device,\n",
    "            attention_mask_keyword=attention_mask_keyword,\n",
    "            normalize_p=normalize_p,\n",
    "            normalize_dim=normalize_dim,\n",
    "        ).cpu()\n",
    "        # print(f'chunk_embeddings.shape = {chunk_embeddings.shape}')\n",
    "        for chunk_i in range(len(chunk)):\n",
    "            unique_text_2_embedding[chunk[chunk_i]] = chunk_embeddings[chunk_i]\n",
    "\n",
    "    return unique_text_2_embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_texts) = 124568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:08<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "text_2_emb_train:Dict[str, torch.Tensor] = transcriptions_series_to_text_2_emb(\n",
    "    transcriptions_series=raw_crowd_train[SPEAKER_TEXT_FIELD_NAME],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    num_chunks=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "не надо не надо не надо не надо                   tensor([ 0.0409,  0.0645, -0.0062,  ...,  0.01...\n",
       "фозил кори mp три                                 tensor([-0.0066,  0.0331,  0.0023,  ...,  0.01...\n",
       "сколько стоит на керамбит                         tensor([ 0.0246,  0.0035,  0.0029,  ..., -0.02...\n",
       "афина когда закончится эта телепередача           tensor([ 0.0242,  0.0469,  0.0188,  ...,  0.01...\n",
       "где проживают дети путина тихонова и воронцова    tensor([-0.0016, -0.0451, -0.0002,  ...,  0.05...\n",
       "dtype: object"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_2_emb_series_train:pd.Series = pd.Series(index=text_2_emb_train.keys(), data=map(repr, text_2_emb_train.values()))\n",
    "text_2_emb_series_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_2_emb_train, PROCESSED_DUSHA_CROWD_TRAIN_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data01/vvkiselev/data/other/dpl/processed/dusha/crowd/train/text_embeddings/v1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[332]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the dictionary from the file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m loaded_dict = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROCESSED_DUSHA_CROWD_TRAIN_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mlist\u001b[39m(loaded_dict.items())[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m].shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dpl/venv/lib64/python3.11/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dpl/venv/lib64/python3.11/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/dpl/venv/lib64/python3.11/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/data01/vvkiselev/data/other/dpl/processed/dusha/crowd/train/text_embeddings/v1.pt'"
     ]
    }
   ],
   "source": [
    "# Load the dictionary from the file\n",
    "# loaded_dict = torch.load(PROCESSED_DUSHA_CROWD_TRAIN_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH, weights_only=False)\n",
    "# list(loaded_dict.items())[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(unique_texts) = 16628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.82it/s]\n"
     ]
    }
   ],
   "source": [
    "text_2_emb_test:Dict[str, torch.Tensor] = transcriptions_series_to_text_2_emb(\n",
    "    transcriptions_series=raw_crowd_test[SPEAKER_TEXT_FIELD_NAME],\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    num_chunks=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(text_2_emb_test, PROCESSED_DUSHA_CROWD_TEST_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict = torch.load(PROCESSED_DUSHA_CROWD_TEST_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH, weights_only=False)\n",
    "list(loaded_dict.items())[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESSED_DUSHA_CROWD_TEST_TEXT_EMBEDDINGS_LAST_VERSION_FILE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
