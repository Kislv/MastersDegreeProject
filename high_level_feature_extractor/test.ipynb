{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wave\n",
    "from scipy.fft import rfft, irfft\n",
    "import sys\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from dataclasses import (\n",
    "    dataclass,\n",
    ")\n",
    "from typing import (\n",
    "    Optional,\n",
    ")\n",
    "from bdw.check import Check\n",
    "\n",
    "sys.path.append('..')\n",
    "from audio import Audio\n",
    "from text.profanity import (\n",
    "    PROFANITY_WORD_FILTER_LANG_NAME,\n",
    ")\n",
    "from volume.human_speech import (\n",
    "    HUMAN_SPEECH_FREQ_BOTTOM,\n",
    "    HUMAN_SPEECH_FREQ_TOP,\n",
    "    HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    ")\n",
    "from configs.base import (\n",
    "    RB_FILE_READING_MODE,\n",
    ")\n",
    "from processing.text.normalization import (\n",
    "    normalized_tokens_2_normalized_text,\n",
    "    text_2_normalized_text,\n",
    ")\n",
    "from high_level_feature_extractor.text.profanity import (\n",
    "    text_2_is_contain_swear_words,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_AUDIO_PATH:Path = Path('/data/vkiselev/data/other/univer/deploma/dusha/crowd/crowd_train/wavs/00000d522439136554c888f4cfd92131.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=82560, data=array([  0,   0,   0, ..., -17, -18, -16], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_example:Audio = Audio.wav_file_path_init(path=EXAMPLE_AUDIO_PATH)\n",
    "audio_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=82560, data=array([  6,   6,   6, ..., -10, -11,  -9], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def speech_filter(\n",
    "    audio:Audio, \n",
    "    low_freq=HUMAN_SPEECH_FREQ_BOTTOM, \n",
    "    high_freq=HUMAN_SPEECH_FREQ_TOP,\n",
    "    )->Audio:\n",
    "\n",
    "    fft_result:np.ndarray = rfft(audio.data)\n",
    "    fft_result_filtered:np.ndarray = fft_result.copy()\n",
    "    freqs:np.ndarray = np.fft.fftfreq(audio.n_frames, d=1.0/audio.sr)\n",
    "\n",
    "    positive_freqs:np.ndarray = freqs[:len(freqs) // 2 + 1]\n",
    "\n",
    "    for i, freq in enumerate(positive_freqs):\n",
    "        if abs(freq) > high_freq or abs(freq) < low_freq:\n",
    "            fft_result_filtered[i] = 0\n",
    "\n",
    "    filtered_signal:np.ndarray = irfft(fft_result_filtered)\n",
    "    sample_dtype:type = audio.sample_dtype()\n",
    "    filtered_signal:np.ndarray = filtered_signal.astype(sample_dtype) \n",
    "    return audio.new_data_copy(data=filtered_signal)\n",
    "\n",
    "audio_filtered = speech_filter(audio=audio_example)\n",
    "\n",
    "speech_filter(audio=audio_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_volume(\n",
    "    audio_path:Path,\n",
    "    )->np.float64:\n",
    "    try:\n",
    "        data, rate = sf.read(audio_path)\n",
    "        meter:pyln.meter.Meter = pyln.Meter(rate)\n",
    "        return meter.integrated_loudness(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "loudness = audio_volume(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-27.88527535926921)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, int)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, rate = sf.read(EXAMPLE_AUDIO_PATH)\n",
    "type(data), type(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.027629564595984295)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wav_path_2_HF_power_ratio(\n",
    "    file_path:Path,\n",
    "    HF_threshold:int = HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    "    )->np.float64:\n",
    "    sampling_rate, signal = wavfile.read(file_path)\n",
    "    # Normalize to [-1, 1]\n",
    "    signal:np.ndarray = signal / np.max(np.abs(signal))\n",
    "\n",
    "    # Apply Hann window\n",
    "    window:np.ndarray = np.hanning(len(signal))\n",
    "    signal_windowed:np.ndarray = signal * window\n",
    "\n",
    "    n:int = len(signal_windowed)\n",
    "    freq_magnitudes:np.ndarray = np.abs(np.fft.fft(signal_windowed))\n",
    "    freqs:np.ndarray = np.fft.fftfreq(n, d=1/sampling_rate)\n",
    "\n",
    "    # Keep only positive frequencies (half the spectrum)\n",
    "    positive_freqs:np.ndarray = freqs[:n//2]\n",
    "    positive_magnitudes:np.ndarray = freq_magnitudes[:n//2]\n",
    "\n",
    "    # Convert magnitudes to power (energy)\n",
    "    power_spectrum:np.ndarray = positive_magnitudes ** 2\n",
    "\n",
    "    total_energy:np.float64 = np.sum(power_spectrum)\n",
    "    high_freq_mask:np.ndarray = positive_freqs > HF_threshold  # Adjust threshold as needed\n",
    "    high_freq_energy:np.float64 = np.sum(power_spectrum[high_freq_mask])\n",
    "\n",
    "    ratio:np.float64 = high_freq_energy / total_energy\n",
    "    return ratio \n",
    "\n",
    "wav_path_2_HF_power_ratio(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HighLevelSpeechFeatures:\n",
    "    loudness: np.float64\n",
    "    HF_power_ratio:np.float64\n",
    "    @classmethod\n",
    "    def wav_path_init(\n",
    "        path:Path,\n",
    "        transcription:Optional[str] = None,\n",
    "        ):\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text:str = 'Нормально пизды сегодня!'\n",
    "\n",
    "text_2_is_contain_swear_words(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
