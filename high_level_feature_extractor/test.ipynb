{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wave\n",
    "from scipy.fft import rfft, irfft\n",
    "import sys\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from dataclasses import (\n",
    "    dataclass,\n",
    ")\n",
    "from typing import (\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "sys.path.append('..')\n",
    "from audio import Audio\n",
    "from volume.human_speech import (\n",
    "    HUMAN_SPEECH_FREQ_BOTTOM,\n",
    "    HUMAN_SPEECH_FREQ_TOP,\n",
    "    HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    ")\n",
    "from configs.base import (\n",
    "    RB_FILE_READING_MODE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_AUDIO_PATH:Path = Path('/data/vkiselev/data/other/univer/deploma/dusha/crowd/crowd_train/wavs/00000d522439136554c888f4cfd92131.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=85120, data=array([  0,   0,   0, ..., -10,   1,  -1], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_example:Audio = Audio.wav_file_path_init(path=EXAMPLE_AUDIO_PATH)\n",
    "audio_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=85120, data=array([ 1,  1,  1, ..., -4,  2,  0], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def speech_filter(\n",
    "    audio:Audio, \n",
    "    low_freq=HUMAN_SPEECH_FREQ_BOTTOM, \n",
    "    high_freq=HUMAN_SPEECH_FREQ_TOP,\n",
    "    )->Audio:\n",
    "\n",
    "    fft_result:np.ndarray = rfft(audio.data)\n",
    "    fft_result_filtered:np.ndarray = fft_result.copy()\n",
    "    freqs:np.ndarray = np.fft.fftfreq(audio.n_frames, d=1.0/audio.sr)\n",
    "\n",
    "    positive_freqs:np.ndarray = freqs[:len(freqs) // 2 + 1]\n",
    "\n",
    "    for i, freq in enumerate(positive_freqs):\n",
    "        if abs(freq) > high_freq or abs(freq) < low_freq:\n",
    "            fft_result_filtered[i] = 0\n",
    "\n",
    "    filtered_signal:np.ndarray = irfft(fft_result_filtered)\n",
    "    sample_dtype:type = audio.sample_dtype()\n",
    "    filtered_signal:np.ndarray = filtered_signal.astype(sample_dtype) \n",
    "    return audio.new_data_copy(data=filtered_signal)\n",
    "\n",
    "audio_filtered = speech_filter(audio=audio_example)\n",
    "\n",
    "speech_filter(audio=audio_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_volume(\n",
    "    audio_path:Path,\n",
    "    )->np.float64:\n",
    "    try:\n",
    "        data, rate = sf.read(audio_path)\n",
    "        meter:pyln.meter.Meter = pyln.Meter(rate)\n",
    "        return meter.integrated_loudness(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "loudness = audio_volume(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-45.12517989530321)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, int)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, rate = sf.read(EXAMPLE_AUDIO_PATH)\n",
    "type(data), type(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.024670111756333636)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wav_path_2_HF_power_ratio(\n",
    "    file_path:Path,\n",
    "    HF_threshold:int = HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    "    )->np.float64:\n",
    "    sampling_rate, signal = wavfile.read(file_path)\n",
    "    # Normalize to [-1, 1]\n",
    "    signal:np.ndarray = signal / np.max(np.abs(signal))\n",
    "\n",
    "    # Apply Hann window\n",
    "    window:np.ndarray = np.hanning(len(signal))\n",
    "    signal_windowed:np.ndarray = signal * window\n",
    "\n",
    "    n:int = len(signal_windowed)\n",
    "    freq_magnitudes:np.ndarray = np.abs(np.fft.fft(signal_windowed))\n",
    "    freqs:np.ndarray = np.fft.fftfreq(n, d=1/sampling_rate)\n",
    "\n",
    "    # Keep only positive frequencies (half the spectrum)\n",
    "    positive_freqs:np.ndarray = freqs[:n//2]\n",
    "    positive_magnitudes:np.ndarray = freq_magnitudes[:n//2]\n",
    "\n",
    "    # Convert magnitudes to power (energy)\n",
    "    power_spectrum:np.ndarray = positive_magnitudes ** 2\n",
    "\n",
    "    total_energy:np.float64 = np.sum(power_spectrum)\n",
    "    high_freq_mask:np.ndarray = positive_freqs > HF_threshold  # Adjust threshold as needed\n",
    "    high_freq_energy:np.float64 = np.sum(power_spectrum[high_freq_mask])\n",
    "\n",
    "    ratio:np.float64 = high_freq_energy / total_energy\n",
    "    return ratio \n",
    "\n",
    "wav_path_2_HF_power_ratio(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HighLevelSpeechFeatures:\n",
    "    loudness: np.float64\n",
    "    HF_power_ratio:np.float64\n",
    "    @classmethod\n",
    "    def wav_path_init(\n",
    "        path:Path,\n",
    "        transcription:Optional[str] = None,\n",
    "        ):\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bdw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpt/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbdw\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheck\u001b[39;00m \u001b[39mimport\u001b[39;00m Check\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpt/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Initialize the filter for Russian language\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpt/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m filter_ru \u001b[39m=\u001b[39m Check(languages\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mru\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bdw'"
     ]
    }
   ],
   "source": [
    "from bdw.check import Check\n",
    "\n",
    "# Initialize the filter for Russian language\n",
    "filter_ru = Check(languages=['ru'])\n",
    "\n",
    "# Input text to check\n",
    "text:str = 'Нормально сегодня отдохнул!'\n",
    "\n",
    "# Check if the text contains obscene words\n",
    "if filter_ru.filter_profanity(text, language='ru'):\n",
    "    print(\"Текст содержит ненормативную лексику.\")\n",
    "else:\n",
    "    print(\"Текст не содержит ненормативной лексики.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/FlacSy/bdw.git\n",
      "  Cloning https://github.com/FlacSy/bdw.git to /tmp/pip-req-build-1pgiko62\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/FlacSy/bdw.git /tmp/pip-req-build-1pgiko62\n",
      "  remote: Repository not found.\n",
      "  fatal: Authentication failed for 'https://github.com/FlacSy/bdw.git/'\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/FlacSy/bdw.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-1pgiko62\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/FlacSy/bdw.git\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-1pgiko62\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/FlacSy/bdw.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
