{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wave\n",
    "import sys\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from dataclasses import (\n",
    "    dataclass,\n",
    ")\n",
    "from typing import (\n",
    "    Optional,\n",
    "    Callable,\n",
    ")\n",
    "from bdw.check import Check\n",
    "\n",
    "sys.path.append('..')\n",
    "from audio import Audio\n",
    "from text.profanity import (\n",
    "    PROFANITY_WORD_FILTER_LANG_NAME,\n",
    ")\n",
    "from configs.base import (\n",
    "    RB_FILE_READING_MODE,\n",
    ")\n",
    "from processing.text.normalization import (\n",
    "    normalized_tokens_2_normalized_text,\n",
    "    text_2_normalized_text,\n",
    ")\n",
    "from high_level_feature_extractor.text.profanity import (\n",
    "    text_2_is_contain_swear_words,\n",
    ")\n",
    "from extractor import (\n",
    "    HighLevelSpeechFeatures,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_AUDIO_PATH:Path = Path('/data/vkiselev/data/other/univer/deploma/dusha/crowd/crowd_train/wavs/00000d522439136554c888f4cfd92131.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=82560, data=array([  0,   0,   0, ..., -17, -18, -16], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_example:Audio = Audio.wav_file_path_init(path=EXAMPLE_AUDIO_PATH)\n",
    "audio_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   0.,   0.,  ..., -17., -18., -16.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# torch.Tensor(audio_example.data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Боже, две семьдесят двадцать!']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_example.transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=82560, data=array([  6,   6,   6, ..., -10, -11,  -9], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "audio_filtered = HighLevelSpeechFeatures.speech_filter(audio=audio_example)\n",
    "\n",
    "HighLevelSpeechFeatures.speech_filter(audio=audio_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighLevelSpeechFeatures(loudness=np.float64(62.286087665088935), HF_power_ratio=np.float64(0.027629564595984295))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HighLevelSpeechFeatures.wav_path_init(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text:str = 'Нормально пизды сегодня!'\n",
    "\n",
    "text_2_is_contain_swear_words(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
