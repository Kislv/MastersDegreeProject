{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import wave\n",
    "from scipy.fft import rfft, irfft\n",
    "import sys\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "from pydub import AudioSegment\n",
    "from scipy.io import wavfile\n",
    "from dataclasses import (\n",
    "    dataclass,\n",
    ")\n",
    "from typing import (\n",
    "    Optional,\n",
    ")\n",
    "from bdw.check import Check\n",
    "# from bdw.check import Check\n",
    "\n",
    "sys.path.append('..')\n",
    "from audio import Audio\n",
    "from text.profanity import (\n",
    "    PROFANITY_WORD_FILTER_LANG_NAME,\n",
    ")\n",
    "from volume.human_speech import (\n",
    "    HUMAN_SPEECH_FREQ_BOTTOM,\n",
    "    HUMAN_SPEECH_FREQ_TOP,\n",
    "    HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    ")\n",
    "from configs.base import (\n",
    "    RB_FILE_READING_MODE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpt/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpt/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_rows\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpt/home/vkiselev/projects/univer/deploma/MastersDegreeProject/high_level_feature_extractor/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_AUDIO_PATH:Path = Path('/data/vkiselev/data/other/univer/deploma/dusha/crowd/crowd_train/wavs/00000d522439136554c888f4cfd92131.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=82560, data=array([  0,   0,   0, ..., -17, -18, -16], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_example:Audio = Audio.wav_file_path_init(path=EXAMPLE_AUDIO_PATH)\n",
    "audio_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Audio(sample_width=2, sr=16000, n_frames=82560, data=array([  6,   6,   6, ..., -10, -11,  -9], dtype=int16), n_channels=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def speech_filter(\n",
    "    audio:Audio, \n",
    "    low_freq=HUMAN_SPEECH_FREQ_BOTTOM, \n",
    "    high_freq=HUMAN_SPEECH_FREQ_TOP,\n",
    "    )->Audio:\n",
    "\n",
    "    fft_result:np.ndarray = rfft(audio.data)\n",
    "    fft_result_filtered:np.ndarray = fft_result.copy()\n",
    "    freqs:np.ndarray = np.fft.fftfreq(audio.n_frames, d=1.0/audio.sr)\n",
    "\n",
    "    positive_freqs:np.ndarray = freqs[:len(freqs) // 2 + 1]\n",
    "\n",
    "    for i, freq in enumerate(positive_freqs):\n",
    "        if abs(freq) > high_freq or abs(freq) < low_freq:\n",
    "            fft_result_filtered[i] = 0\n",
    "\n",
    "    filtered_signal:np.ndarray = irfft(fft_result_filtered)\n",
    "    sample_dtype:type = audio.sample_dtype()\n",
    "    filtered_signal:np.ndarray = filtered_signal.astype(sample_dtype) \n",
    "    return audio.new_data_copy(data=filtered_signal)\n",
    "\n",
    "audio_filtered = speech_filter(audio=audio_example)\n",
    "\n",
    "speech_filter(audio=audio_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_volume(\n",
    "    audio_path:Path,\n",
    "    )->np.float64:\n",
    "    try:\n",
    "        data, rate = sf.read(audio_path)\n",
    "        meter:pyln.meter.Meter = pyln.Meter(rate)\n",
    "        return meter.integrated_loudness(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "loudness = audio_volume(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-27.88527535926921)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, int)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, rate = sf.read(EXAMPLE_AUDIO_PATH)\n",
    "type(data), type(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.027629564595984295)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wav_path_2_HF_power_ratio(\n",
    "    file_path:Path,\n",
    "    HF_threshold:int = HIGH_FREQUENCY_SPEECH_THRESHOLD,\n",
    "    )->np.float64:\n",
    "    sampling_rate, signal = wavfile.read(file_path)\n",
    "    # Normalize to [-1, 1]\n",
    "    signal:np.ndarray = signal / np.max(np.abs(signal))\n",
    "\n",
    "    # Apply Hann window\n",
    "    window:np.ndarray = np.hanning(len(signal))\n",
    "    signal_windowed:np.ndarray = signal * window\n",
    "\n",
    "    n:int = len(signal_windowed)\n",
    "    freq_magnitudes:np.ndarray = np.abs(np.fft.fft(signal_windowed))\n",
    "    freqs:np.ndarray = np.fft.fftfreq(n, d=1/sampling_rate)\n",
    "\n",
    "    # Keep only positive frequencies (half the spectrum)\n",
    "    positive_freqs:np.ndarray = freqs[:n//2]\n",
    "    positive_magnitudes:np.ndarray = freq_magnitudes[:n//2]\n",
    "\n",
    "    # Convert magnitudes to power (energy)\n",
    "    power_spectrum:np.ndarray = positive_magnitudes ** 2\n",
    "\n",
    "    total_energy:np.float64 = np.sum(power_spectrum)\n",
    "    high_freq_mask:np.ndarray = positive_freqs > HF_threshold  # Adjust threshold as needed\n",
    "    high_freq_energy:np.float64 = np.sum(power_spectrum[high_freq_mask])\n",
    "\n",
    "    ratio:np.float64 = high_freq_energy / total_energy\n",
    "    return ratio \n",
    "\n",
    "wav_path_2_HF_power_ratio(EXAMPLE_AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HighLevelSpeechFeatures:\n",
    "    loudness: np.float64\n",
    "    HF_power_ratio:np.float64\n",
    "    @classmethod\n",
    "    def wav_path_init(\n",
    "        path:Path,\n",
    "        transcription:Optional[str] = None,\n",
    "        ):\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install from GitHub: pip install git+https://github.com/FlacSy/bdw.git\n",
    "\n",
    "# Configure for Russian detection\n",
    "profanity_check = Check(languages=['ru'])\n",
    "\n",
    "# Check text\n",
    "text = \"Проверяемый текст с нецензурщиной\"\n",
    "is_obscene = profanity_check.filter_profanity(text, language='ru')\n",
    "\n",
    "if is_obscene:\n",
    "    print(\"Text contains Russian obscenities\")\n",
    "else:\n",
    "    print(\"Text is clean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text:str = 'Нормально хуй сегодня!'\n",
    "\n",
    "#TODO normalization from ipynb to scripts\n",
    "def normalized_text_2_is_contain_swear_words(\n",
    "    text:str,\n",
    "    lang:str = PROFANITY_WORD_FILTER_LANG_NAME,\n",
    "    ):\n",
    "    filter:bdw.check.Check = Check(languages=[lang])\n",
    "    return filter.filter_profanity(text, language=lang)\n",
    "    \n",
    "normalized_text_2_is_contain_swear_words(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
